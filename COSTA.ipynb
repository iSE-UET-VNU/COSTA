{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L3uwGy0LnsQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Vulnerability_Detection/Statement_Level')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "1avnp4SCZoFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "NPI7mMJucHhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Word2Vec model"
      ],
      "metadata": {
        "id": "_gRiESTNLDL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Word2VecTrain import *\n",
        "from gensim.models import KeyedVectors\n",
        "from helper import *\n",
        "from STM_classification_manager import *\n",
        "import pandas \n",
        "vector_length = 96\n",
        "\n",
        "training_data = pandas.read_csv(\"Data/train.csv\", encoding='utf-8')\n",
        "validating_data = pandas.read_csv(\"Data/val.csv\", encoding='utf-8')\n",
        "\n",
        "data = pandas.concat([training_data, validating_data]) \n",
        "data = data.reset_index(drop=True) \n",
        "\n",
        "vectorizer = Word2VecTrain(vector_length, \"Data/results/word2vec.wordvectors\")\n",
        "count = 0\n",
        "for df_idx, row in data.iterrows():\n",
        "        count += 1\n",
        "\n",
        "        print(\"Collecting gadgets...\", count, end=\"\\r\")\n",
        "        \n",
        "        pre_surrounding_context = get_context(data.at[df_idx,\"surrounding_ctx_code_pred\"], data.at[df_idx,\"surrounding_ctx_code_succ\"])\n",
        "        bw_cdg_context = get_context(data.at[df_idx,\"cdg_bw_slicing\"], data.at[df_idx,\"cdg_fw_slicing\"])\n",
        "        bw_ddg_context = get_context(data.at[df_idx,\"ddg_bw_slicing\"], data.at[df_idx,\"ddg_fw_slicing\"])\n",
        "        operation_ctx_abstract = get_operation_context(data.at[df_idx,\"operation_ctx\"])\n",
        "        vul_type = data.at[df_idx,\"vul_type\"]\n",
        "        vectorizer.add_gadget([pre_surrounding_context, bw_cdg_context, bw_ddg_context, operation_ctx_abstract])\n",
        "    \n",
        "vectorizer.train_model()"
      ],
      "metadata": {
        "id": "QufHXyDHLCZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Representation learning"
      ],
      "metadata": {
        "id": "xz48-qlE7bdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from STM_classification_manager import *\n",
        "from STM_blstm import *\n",
        "from Result_Manager import *\n",
        "from gensim.models import KeyedVectors\n",
        "import pandas as pd\n",
        "vector_length = 96\n",
        "max_seq_length = 400\n",
        "max_code_stmt_length = 20\n",
        "\n",
        "def main():\n",
        "    vectorizer =  KeyedVectors.load(\"Data/results/word2vec.wordvectors\", mmap='r')\n",
        "    blstm = STM_Train_BLSTM(vectorizer, data_file=\"Data/sampled_train.csv\",name=\"word2vec\", vector_length = vector_length, max_seq_length=max_seq_length, max_code_stmt_length=max_code_stmt_length, batch_size = 64)\n",
        "    blstm.train(epochs=50)\n",
        "    blstm = STM_Test_BLSTM(vectorizer, data_file=\"Data/test.csv\",name=\"word2vec\",vector_length = vector_length, max_seq_length=max_seq_length, max_code_stmt_length=max_code_stmt_length, batch_size = 64)\n",
        "    predictions, targets = blstm.test()\n",
        "\n",
        "    classification_accuracy_report(predictions, targets, 0.5)\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "Vz3yYkfMbqB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}